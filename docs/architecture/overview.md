# Architecture Overview

## Executive Summary

contribux is an AI-powered GitHub contribution discovery platform built with a **serverless-first**, **AI-native** architecture. The system is designed for zero maintenance overhead while providing intelligent, personalized contribution recommendations to senior developers transitioning to AI Engineering roles.

## High-Level Architecture

```mermaid
graph TB
    subgraph "ðŸŒ External Services"
        GH[GitHub API v4]
        OAI[OpenAI API]
        RS[Resend Email]
        TX[Telnyx SMS]
    end

    subgraph "ðŸŽ¨ Frontend Layer"
        PWA[Next.js 15 PWA]
        RSC[React Server Components]
        UI[shadcn/ui Components]
        TW[Tailwind CSS 4.0]
    end

    subgraph "ðŸ”Œ API Layer"
        EF[Vercel Edge Functions]
        TR[tRPC v11 Router]
        MW[Auth Middleware]
        RL[Rate Limiting]
    end

    subgraph "ðŸ¤– AI Intelligence Layer"
        OR[Agent Orchestrator]
        SC[Repository Scanner]
        AN[AI Analyzer]
        ST[Strategist]
        PE[Personalization Engine]
    end

    subgraph "ðŸ’¾ Data Layer"
        PG[(Neon PostgreSQL 16)]
        VE[pgvector Embeddings]
        RD[(Upstash Redis)]
        QS[QStash Queue]
    end

    subgraph "ðŸ“Š Observability"
        VA[Vercel Analytics]
        SE[Sentry Monitoring]
        LH[Lighthouse CI]
    end

    %% Connections
    PWA --> EF
    EF --> TR
    TR --> MW
    MW --> OR

    OR --> SC
    OR --> AN
    OR --> ST
    OR --> PE

    SC --> GH
    AN --> OAI
    PE --> RD

    MW --> PG
    AN --> VE
    SC --> QS

    PE --> RS
    PE --> TX

    EF --> VA
    AN --> SE
    PWA --> LH

    %% Styling
    style PWA fill:#7C3AED,color:#fff
    style OR fill:#10B981,color:#fff
    style PG fill:#F59E0B,color:#fff
    style OAI fill:#EF4444,color:#fff
```

## Core Architectural Principles

### 1. Serverless-First Design

- **Zero Infrastructure Management**: No servers to maintain or scale
- **Automatic Scaling**: Handles traffic spikes without manual intervention
- **Pay-per-Use**: Cost scales with actual usage, not reserved capacity
- **Global Distribution**: Edge functions deployed worldwide for low latency

### 2. AI-Native Architecture

- **LLM-First Design**: Built around large language model capabilities
- **Agent-Based Processing**: Specialized AI agents for different tasks
- **Vector-Powered Search**: Semantic similarity using embeddings
- **Continuous Learning**: System improves through user feedback

### 3. Event-Driven Processing

```mermaid
sequenceDiagram
    participant GH as GitHub
    participant WH as Webhook
    participant Q as Queue
    participant AI as AI Agent
    participant DB as Database
    participant U as User

    GH->>WH: Issue Created
    WH->>Q: Queue Analysis
    Q->>AI: Process Opportunity
    AI->>AI: Analyze & Score
    AI->>DB: Store Results
    DB->>U: Smart Notification
```

### 4. Performance Optimization

- **Edge Computing**: Sub-50ms latency worldwide
- **Intelligent Caching**: Multi-layer caching strategy
- **Bundle Optimization**: Code splitting and lazy loading
- **Database Optimization**: Vector indexes and query optimization

## Technology Stack Layers

### Frontend Technologies

```mermaid
graph LR
    subgraph "UI Framework"
        N[Next.js 15] --> R[React 19]
        R --> T[TypeScript 5.7+]
    end

    subgraph "Styling"
        TW[Tailwind CSS 4.0] --> SH[shadcn/ui 2.0]
        SH --> RA[Radix Primitives]
    end

    subgraph "State Management"
        SW[SWR v3] --> RC[React Context]
        RC --> ZU[Zustand]
    end

    style N fill:#7C3AED,color:#fff
    style T fill:#10B981,color:#fff
    style TW fill:#F59E0B,color:#fff
```

### Backend Technologies

```mermaid
graph LR
    subgraph "Runtime"
        VE[Vercel Edge] --> TR[tRPC v11]
        TR --> ZO[Zod Validation]
    end

    subgraph "Database"
        NE[Neon PostgreSQL] --> PV[pgvector 0.7]
        PV --> HS[HNSW Indexes]
    end

    subgraph "AI/ML"
        OA[OpenAI Agents SDK] --> GP[GPT-4o-mini]
        GP --> EM[Embeddings API]
    end

    style VE fill:#7C3AED,color:#fff
    style NE fill:#F59E0B,color:#fff
    style OA fill:#10B981,color:#fff
```

## Data Flow Architecture

### Real-Time Processing Pipeline

```mermaid
graph TD
    A[GitHub Event] --> B{Event Type}
    B -->|Issue Created| C[Issue Analyzer]
    B -->|PR Merged| D[Success Tracker]
    B -->|Repo Updated| E[Health Calculator]

    C --> F[AI Analysis Queue]
    D --> G[Learning Pipeline]
    E --> H[Repository Update]

    F --> I[Opportunity Scoring]
    G --> J[Recommendation Tuning]
    H --> K[Health Score Update]

    I --> L[User Matching]
    J --> M[Personalization Update]
    K --> N[Search Index Update]

    L --> O[Smart Notification]
    M --> P[Preference Learning]
    N --> Q[Discovery Enhancement]

    style F fill:#10B981,color:#fff
    style L fill:#F59E0B,color:#fff
    style O fill:#EF4444,color:#fff
```

### Batch Processing Workflow

```mermaid
graph TB
    subgraph "Daily Processing"
        A[Repository Scanner] --> B[Trending Analysis]
        B --> C[Health Scoring]
        C --> D[Opportunity Discovery]
    end

    subgraph "AI Processing"
        D --> E[Embedding Generation]
        E --> F[Content Analysis]
        F --> G[Complexity Scoring]
    end

    subgraph "User Matching"
        G --> H[Preference Matching]
        H --> I[Skill Alignment]
        I --> J[Notification Queue]
    end

    subgraph "Analytics"
        K[Usage Metrics] --> L[Performance Analysis]
        L --> M[Quality Metrics]
        M --> N[Optimization Insights]
    end

    style E fill:#10B981,color:#fff
    style H fill:#F59E0B,color:#fff
    style L fill:#7C3AED,color:#fff
```

## AI Agent Architecture

### Agent Orchestration

```mermaid
graph TB
    subgraph "ðŸŽ¯ Orchestration Layer"
        OR[ContribuxOrchestrator]
        OR --> TR[Task Router]
        OR --> SM[State Manager]
        OR --> EH[Error Handler]
    end

    subgraph "ðŸ” Discovery Agents"
        SC[Scanner Agent] --> RH[Repository Health]
        SC --> ID[Issue Discovery]
        SC --> TA[Trend Analysis]
    end

    subgraph "ðŸ§  Analysis Agents"
        AN[Analyzer Agent] --> CE[Complexity Estimator]
        AN --> SD[Skill Detector]
        AN --> AP[Acceptance Predictor]
    end

    subgraph "ðŸ’¡ Strategy Agents"
        ST[Strategist Agent] --> IP[Implementation Planner]
        ST --> RA[Risk Assessor]
        ST --> SP[Success Predictor]
    end

    subgraph "ðŸ“ˆ Learning Agents"
        LE[Learning Agent] --> PA[Pattern Analyzer]
        LE --> RT[Recommendation Tuner]
        LE --> QA[Quality Assessor]
    end

    OR --> SC
    OR --> AN
    OR --> ST
    OR --> LE

    SC --> AN
    AN --> ST
    ST --> LE

    style OR fill:#7C3AED,color:#fff
    style AN fill:#10B981,color:#fff
    style ST fill:#F59E0B,color:#fff
    style LE fill:#EF4444,color:#fff
```

### Agent Communication Flow

```mermaid
sequenceDiagram
    participant O as Orchestrator
    participant S as Scanner
    participant A as Analyzer
    participant St as Strategist
    participant L as Learner

    O->>S: Scan Repository
    S->>S: Analyze Health
    S->>O: Health Report

    O->>A: Analyze Opportunities
    A->>A: Process Issues
    A->>O: Analysis Results

    O->>St: Generate Strategy
    St->>St: Plan Implementation
    St->>O: Strategy Report

    O->>L: Update Learning
    L->>L: Analyze Patterns
    L->>O: Insights

    Note over O,L: Continuous feedback loop
```

## Security Architecture

### Authentication & Authorization

```mermaid
graph TB
    subgraph "ðŸ” Authentication Flow"
        A[User Request] --> B[GitHub OAuth]
        B --> C[JWT Token]
        C --> D[Session Management]
    end

    subgraph "ðŸ›¡ï¸ Security Layers"
        E[Rate Limiting] --> F[Input Validation]
        F --> G[Authorization Check]
        G --> H[Audit Logging]
    end

    subgraph "ðŸ”’ Data Protection"
        I[TLS 1.3] --> J[AES-256 Encryption]
        J --> K[Token Encryption]
        K --> L[PII Minimization]
    end

    A --> E
    D --> G
    C --> K

    style B fill:#10B981,color:#fff
    style G fill:#F59E0B,color:#fff
    style J fill:#EF4444,color:#fff
```

### Security Controls

- **Transport Security**: TLS 1.3 for all communications
- **Authentication**: GitHub OAuth 2.0 with PKCE
- **Authorization**: JWT tokens with 15-minute expiry
- **Input Validation**: Zod schemas for runtime type checking
- **Rate Limiting**: Per-user and per-endpoint protection
- **Data Encryption**: AES-256-GCM for sensitive data at rest

## Performance Architecture

### Caching Strategy

```mermaid
graph LR
    subgraph "ðŸŒ CDN Layer"
        A[Vercel Edge Cache] --> B[Static Assets]
        A --> C[API Responses]
    end

    subgraph "ðŸš€ Application Cache"
        D[SWR Client Cache] --> E[Component State]
        D --> F[API Data]
    end

    subgraph "ðŸ’¾ Database Cache"
        G[Redis Cache] --> H[Query Results]
        G --> I[Session Data]
    end

    subgraph "ðŸ—„ï¸ Database"
        J[PostgreSQL] --> K[Query Cache]
        J --> L[Connection Pool]
    end

    A --> D
    D --> G
    G --> J

    style A fill:#7C3AED,color:#fff
    style G fill:#10B981,color:#fff
    style J fill:#F59E0B,color:#fff
```

### Performance Targets

| Metric              | Target | Critical |
| ------------------- | ------ | -------- |
| Initial Page Load   | <2s    | <3s      |
| API Response (p95)  | <500ms | <1s      |
| Time to Interactive | <3s    | <5s      |
| Vector Search       | <100ms | <500ms   |
| Background Jobs     | <5min  | <10min   |

## Monitoring and Observability

### Observability Stack

```mermaid
graph TB
    subgraph "ðŸ“Š Metrics Collection"
        A[Vercel Analytics] --> B[Core Web Vitals]
        C[Custom Events] --> D[Business Metrics]
        E[Database Metrics] --> F[Query Performance]
    end

    subgraph "ðŸ› Error Tracking"
        G[Sentry] --> H[Error Aggregation]
        H --> I[Alert Routing]
        I --> J[Incident Response]
    end

    subgraph "âš¡ Performance Monitoring"
        K[Lighthouse CI] --> L[Performance Scores]
        M[APM Traces] --> N[Request Flow]
        O[Database Monitoring] --> P[Slow Queries]
    end

    subgraph "ðŸ“ˆ Business Intelligence"
        Q[User Analytics] --> R[Engagement Metrics]
        S[AI Performance] --> T[Quality Metrics]
        U[Cost Tracking] --> V[Resource Usage]
    end

    style A fill:#7C3AED,color:#fff
    style G fill:#EF4444,color:#fff
    style K fill:#10B981,color:#fff
    style Q fill:#F59E0B,color:#fff
```

### Key Performance Indicators

- **Technical KPIs**: Uptime (99.9%), Response time (<500ms), Error rate (<0.1%)
- **Business KPIs**: User activation (80%), Contribution success (40%), Retention (70%)
- **AI KPIs**: Analysis accuracy (85%), Recommendation relevance (80%), Processing time (<30s)
- **Cost KPIs**: Cost per user (<$0.50), API efficiency, Resource utilization

## Deployment Architecture

### Multi-Environment Strategy

```mermaid
graph TB
    subgraph "ðŸ  Development"
        A[Local Environment] --> B[Hot Reload]
        B --> C[Local PostgreSQL]
        C --> D[Mock Services]
    end

    subgraph "ðŸ” Preview"
        E[PR Deployments] --> F[Neon Branches]
        F --> G[Full Feature Set]
        G --> H[Integration Testing]
    end

    subgraph "ðŸŽ­ Staging"
        I[Staging Environment] --> J[Production Mirror]
        J --> K[Performance Testing]
        K --> L[UAT]
    end

    subgraph "ðŸš€ Production"
        M[Vercel Production] --> N[Edge Distribution]
        N --> O[Auto Scaling]
        O --> P[Monitoring]
    end

    A --> E
    E --> I
    I --> M

    style A fill:#10B981,color:#fff
    style E fill:#F59E0B,color:#fff
    style I fill:#EF4444,color:#fff
    style M fill:#7C3AED,color:#fff
```

### Deployment Pipeline

```mermaid
graph LR
    A[Git Push] --> B[GitHub Actions]
    B --> C[Type Check]
    C --> D[Lint & Test]
    D --> E[Build]
    E --> F[Deploy to Vercel]
    F --> G[Health Check]
    G --> H{Success?}
    H -->|Yes| I[Traffic Switch]
    H -->|No| J[Rollback]

    style B fill:#10B981,color:#fff
    style F fill:#7C3AED,color:#fff
    style J fill:#EF4444,color:#fff
```

## Scalability Considerations

### Horizontal Scaling

- **Serverless Functions**: Automatic scaling based on demand
- **Database**: Neon's automatic read replicas and connection pooling
- **CDN**: Global edge distribution for static assets
- **Queue Processing**: Parallel job execution with QStash

### Vertical Optimization

- **Bundle Optimization**: Code splitting and tree shaking
- **Query Optimization**: Database indexes and query planning
- **Caching**: Multi-layer caching strategy
- **Asset Optimization**: Image compression and format optimization

### Cost Scaling Model

```mermaid
graph LR
    A[100 Users<br/>$0/month] --> B[1K Users<br/>$115/month]
    B --> C[10K Users<br/>$675/month]
    C --> D[100K Users<br/>$4.5K/month]

    style A fill:#10B981,color:#fff
    style B fill:#F59E0B,color:#fff
    style C fill:#EF4444,color:#fff
    style D fill:#7C3AED,color:#fff
```

## Future Architecture Evolution

### Planned Enhancements

1. **Microservices Evolution**: Extract agent services for better scaling
2. **Advanced AI Features**: Fine-tuned models and reinforcement learning
3. **Enterprise Features**: Team collaboration and organization analytics
4. **Global Distribution**: Multi-region deployment for reduced latency

### Technology Roadmap

- **Q2 2025**: Enhanced AI agents with custom models
- **Q3 2025**: Real-time collaboration features
- **Q4 2025**: Enterprise deployment options
- **Q1 2026**: Mobile native applications

This architecture provides a solid foundation for contribux while maintaining flexibility for future growth and technological evolution.
